Project for ASVspoof 2021 

General
----------
This project is for ASVspoof 2021 LA baseline.
But it may be used for PA too

1. lfcc-lcnn-lstm-p2s_toy_example: a toy example to train and run evaluation
2. lfcc-lcnn-lstm-p2s_baseline (to be uploaded after the release of ASVspoof 2021 data)

Usage
----------

1. Using toy dat set to do training and evaluation 
   Either run the single script
   $: bash 00_toy_example.sh

2. Using a quick wrapper to evaluate a new evaluation set
   (although we will use the evaluation set in the toy data set)
   $: bash 00_wrapper_eval.sh

Walking through the first script shows how to use this project to train and evaluate
a data set. It is useful if you want work on real data sets.
Of course, the data set directory and related configuration file must be prepared.
After running 00_toy_example.sh, you will see how the data set is prepared in DATA/toy_example.
And you can check how configuration is done in */config.py


Walking through the second script shows the conveninent way to run evaluation on 
different evaluation sets. Just provide the directory of waveform to be evaluated, 
the trained model, and an arbitary name for the evaluation set. That's all.


Folder structure
----------------
|- DATA
|  |- toy_example
|  |  |- protocol.txt: 
|  |  |   protocol file
|  |  |   this will be loaded by pytorch code for training and evaluation
|  |  |- scp: 
|  |  |   list of files for traing, dev, and eval
|  |  |- train_dev: 
|  |  |   waveform for train and validation sets   
|  |  |- eval: 
|  |  |   waveform for evaluation sets   
|
|- lfcc-lcnn-lstmsum-p2s_toy_example
|  |  folder for the toy example
|  |  |- 00_train.sh: recipe to train the model
|  |  |- 01_eval.sh: command line to evaluate the model on eval set
|  |  |- main.py: main function
|  |  |- config.py: configuration file
|  |  |- model.py: definition of model in Pytorch code
|  |  |- __pretrained
|  |       |- trained_network.pt: pre-trained model 
|  |       |   from ../03-asvspoof-mega/lfcc-lcnn-lstmsum-p2s/04

Note
----------
1. If GPU memory is insufficient, please reduce --batch-size in */00_train.sh

2. Output score has this following format:

   Output, File name, label, score
   Output, LA_E_8688127, 0, -0.011127

   If label of the trial is given in the protocol file, the label will be: 
     0, which denotes spoof
     1, which denotes bona fide
   If label of the trial is not given in the protocol file, the label will be:
    -1, which means unknown (not provided)

3. Accordingly, the code assumes 0 and 1 as the tables for spoof and bona fide
   trials, respectively. 

4. Please check ../03-asvspoof-mega if you want to use other models. 
   However, model.py ../03-asvspoof-mega assumes that trial labels are available 
   for evaluation set (as post-challenge experiments on ASVspoof2019 LA).

   For new evaluation set whose trial labels are unknown, please create
   protocol.txt using dummy labels for the trials. 
   Or, please modify protocol_parse() and _get_target_eval() 
   following lfcc-lcnn-lstm-p2s_toy_example/model.py

   (Apologize that I don't have the time to modify the model.py in 03-asvspoof-mega 
    one by one)
     
5. The used countermeasure model is detailed here https://arxiv.org/abs/2103.11326.


That's all